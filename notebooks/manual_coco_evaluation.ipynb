{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO Evaluating with Ground Truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import os\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting MLFLOW Configurations\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'thesisuist'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'cd6a7567bea2de310e1d52ac2f35483fca241e95'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the tracking URI: DagsHub MLFlow repository\n",
    "mlflow.set_tracking_uri('https://dagshub.com/thesisuist/reversed_final.mlflow')\n",
    "\n",
    "# Getting the Run ID\n",
    "run_id = '6b8969424815419ab706b8aff4de27a8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = mlflow.tracking.MlflowClient().list_artifacts(run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<FileInfo: file_size=None, is_dir=True, path='after_train_config_file'>,\n",
       " <FileInfo: file_size=None, is_dir=True, path='after_training_config_file'>,\n",
       " <FileInfo: file_size=132420, is_dir=False, path='events.out.tfevents.1715871614.gorina9.4186487.0'>,\n",
       " <FileInfo: file_size=132420, is_dir=False, path='events.out.tfevents.1715872291.gorina8.1127786.0'>,\n",
       " <FileInfo: file_size=131971, is_dir=False, path='events.out.tfevents.1716708368.gorina8.4100335.0'>,\n",
       " <FileInfo: file_size=15, is_dir=False, path='last_checkpoint'>,\n",
       " <FileInfo: file_size=44076, is_dir=False, path='loss_curve.png'>,\n",
       " <FileInfo: file_size=262234, is_dir=False, path='metrics.json'>,\n",
       " <FileInfo: file_size=6130, is_dir=False, path='model-config.yaml'>,\n",
       " <FileInfo: file_size=330107348, is_dir=False, path='model_0000499.pth'>,\n",
       " <FileInfo: file_size=330107348, is_dir=False, path='model_0000999.pth'>,\n",
       " <FileInfo: file_size=330107348, is_dir=False, path='model_0001499.pth'>,\n",
       " <FileInfo: file_size=330107348, is_dir=False, path='model_0001999.pth'>,\n",
       " <FileInfo: file_size=330107348, is_dir=False, path='model_0002499.pth'>,\n",
       " <FileInfo: file_size=330107348, is_dir=False, path='model_final.pth'>,\n",
       " <FileInfo: file_size=None, is_dir=True, path='test-set-evaluation'>,\n",
       " <FileInfo: file_size=None, is_dir=True, path='test-set-results'>,\n",
       " <FileInfo: file_size=None, is_dir=True, path='test_images'>,\n",
       " <FileInfo: file_size=395739, is_dir=False, path='training-log.txt'>,\n",
       " <FileInfo: file_size=None, is_dir=True, path='validation-set-evaluation'>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the artifact files of the chosen experiment\n",
    "artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/beegfs/home/aashishk/for_github/notebooks/artifacts/test-set-evaluation/coco_instances_results.json'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.tracking.MlflowClient().download_artifacts(run_id, 'test-set-evaluation/coco_instances_results.json', 'artifacts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Getting the groundtruth test file and the output coco results file\n",
    "cocoGt = COCO(\"../data/Phase II/test.json\")\n",
    "cocoDt = cocoGt.loadRes(\"artifacts/test-set-evaluation/coco_instances_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating and Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.729\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.912\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.822\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.702\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.734\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.433\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.820\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.820\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.779\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.841\n"
     ]
    }
   ],
   "source": [
    "cocoEval = COCOeval(cocoGt, cocoDt, \"bbox\")\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate IoU\n",
    "def calculate_iou(boxA, boxB):\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    - boxA (tuple): A tuple (x, y, width, height) representing the first bounding box.\n",
    "    - boxB (tuple): A tuple (x, y, width, height) representing the second bounding box.\n",
    "\n",
    "    Returns:\n",
    "    - float: The Intersection over Union (IoU) between the two bounding boxes.\n",
    "    \"\"\"\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
    "    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
    "\n",
    "    iArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = boxA[2] * boxA[3]\n",
    "    boxBArea = boxB[2] * boxB[3]\n",
    "\n",
    "    iou = iArea / float(boxAArea + boxBArea - iArea)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For caption\n",
      "True Positives (TP): 185\n",
      "False Positives (FP): 34\n",
      "False Negatives (FN): 7\n",
      "==============================\n",
      "For table\n",
      "True Positives (TP): 192\n",
      "False Positives (FP): 15\n",
      "False Negatives (FN): 2\n",
      "==============================\n",
      "For table_caption\n",
      "True Positives (TP): 190\n",
      "False Positives (FP): 36\n",
      "False Negatives (FN): 0\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Defining Threshold\n",
    "iou_threshold = 0.5\n",
    "\n",
    "# Defaults; Initializing the variables\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "# Fetching Categories / Classes\n",
    "categories = cocoGt.loadCats(cocoGt.getCatIds())\n",
    "\n",
    "for catId in cocoGt.getCatIds():\n",
    "    gt_ann_ids = cocoGt.getAnnIds(catIds=[catId])\n",
    "    dt_ann_ids = cocoDt.getAnnIds(catIds=[catId])\n",
    "\n",
    "    gt_anns = cocoGt.loadAnns(gt_ann_ids)\n",
    "    dt_anns = cocoDt.loadAnns(dt_ann_ids)\n",
    "\n",
    "    matched_gt_ids = set()\n",
    "    matched_dt_ids = set()\n",
    "\n",
    "    for gt in gt_anns:\n",
    "        best_iou = 0\n",
    "        best_dt_id = None\n",
    "        for dt in dt_anns:\n",
    "            iou = calculate_iou(dt['bbox'], gt['bbox'])\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_dt_id = dt['id']\n",
    "        \n",
    "        if best_iou >= iou_threshold:\n",
    "            matched_gt_ids.add(gt['id'])\n",
    "            matched_dt_ids.add(best_dt_id)\n",
    "    \n",
    "    tp = len(matched_gt_ids)\n",
    "    fp = len(dt_anns) - len(matched_dt_ids)\n",
    "    fn = len(gt_anns) - len(matched_gt_ids)\n",
    "\n",
    "    className = cocoGt.loadCats(catId)[0]['name']\n",
    "    print(\"For \" + className)\n",
    "    print(f'True Positives (TP): {tp}')\n",
    "    print(f'False Positives (FP): {fp}')\n",
    "    print(f'False Negatives (FN): {fn}')\n",
    "    print(\"==============================\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
